{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"../data/num_tokens.tsv\"\n",
    "OUTPUT_FILE = \"../configs/llm-jp-4_en_15.6t.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "formatter = get_ipython().display_formatter.formatters[\"text/plain\"]\n",
    "formatter.for_type(np.int64, lambda n, p, cycle: p.text(f\"{n:d}\"))\n",
    "formatter.for_type(np.float64, lambda n, p, cycle: p.text(f\"{n:f}\"))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus/tokenized/code/code_olmo-starcoder_0000</td>\n",
       "      <td>104427769064</td>\n",
       "      <td>code</td>\n",
       "      <td>code_olmo-starcoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus/tokenized/code/code_stack_0000</td>\n",
       "      <td>114051163723</td>\n",
       "      <td>code</td>\n",
       "      <td>code_stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus/tokenized/en/en_dolma-books_0000</td>\n",
       "      <td>5494262694</td>\n",
       "      <td>en</td>\n",
       "      <td>en_dolma-books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus/tokenized/en/en_dolma-pes2o_0000</td>\n",
       "      <td>62853772802</td>\n",
       "      <td>en</td>\n",
       "      <td>en_dolma-pes2o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus/tokenized/en/en_dolma-reddit_0000</td>\n",
       "      <td>83015186637</td>\n",
       "      <td>en</td>\n",
       "      <td>en_dolma-reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>corpus/tokenized/zh/zh_fineweb2_0001</td>\n",
       "      <td>192160217528</td>\n",
       "      <td>zh</td>\n",
       "      <td>zh_fineweb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>corpus/tokenized/zh/zh_fineweb2_0002</td>\n",
       "      <td>191629318921</td>\n",
       "      <td>zh</td>\n",
       "      <td>zh_fineweb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>corpus/tokenized/zh/zh_fineweb2_0003</td>\n",
       "      <td>198652395168</td>\n",
       "      <td>zh</td>\n",
       "      <td>zh_fineweb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>corpus/tokenized/zh/zh_fineweb2_0004</td>\n",
       "      <td>15248244538</td>\n",
       "      <td>zh</td>\n",
       "      <td>zh_fineweb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>corpus/tokenized/zh/zh_wiki_0000</td>\n",
       "      <td>840277331</td>\n",
       "      <td>zh</td>\n",
       "      <td>zh_wiki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filename        tokens language  \\\n",
       "0    corpus/tokenized/code/code_olmo-starcoder_0000  104427769064     code   \n",
       "1             corpus/tokenized/code/code_stack_0000  114051163723     code   \n",
       "2           corpus/tokenized/en/en_dolma-books_0000    5494262694       en   \n",
       "3           corpus/tokenized/en/en_dolma-pes2o_0000   62853772802       en   \n",
       "4          corpus/tokenized/en/en_dolma-reddit_0000   83015186637       en   \n",
       "..                                              ...           ...      ...   \n",
       "323            corpus/tokenized/zh/zh_fineweb2_0001  192160217528       zh   \n",
       "324            corpus/tokenized/zh/zh_fineweb2_0002  191629318921       zh   \n",
       "325            corpus/tokenized/zh/zh_fineweb2_0003  198652395168       zh   \n",
       "326            corpus/tokenized/zh/zh_fineweb2_0004   15248244538       zh   \n",
       "327                corpus/tokenized/zh/zh_wiki_0000     840277331       zh   \n",
       "\n",
       "                  subset  \n",
       "0    code_olmo-starcoder  \n",
       "1             code_stack  \n",
       "2         en_dolma-books  \n",
       "3         en_dolma-pes2o  \n",
       "4        en_dolma-reddit  \n",
       "..                   ...  \n",
       "323          zh_fineweb2  \n",
       "324          zh_fineweb2  \n",
       "325          zh_fineweb2  \n",
       "326          zh_fineweb2  \n",
       "327              zh_wiki  \n",
       "\n",
       "[328 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = pd.read_csv(INPUT_FILE, sep=\"\\t\", dtype={\"filename\": str, \"tokens\": np.int64})\n",
    "\n",
    "stem = num_tokens[\"filename\"].apply(lambda x: x.split(\"/\")[3])\n",
    "num_tokens[\"language\"] = stem.apply(lambda x: x.split(\"_\")[0])\n",
    "num_tokens[\"subset\"] = stem.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select subsets\n",
    "selected_subsets = [\n",
    "    \"code_olmo-starcoder\",\n",
    "    \"code_stack\",\n",
    "    \"en_dolma-books\",\n",
    "    \"en_dolma-pes2o\",\n",
    "    \"en_dolma-reddit\",\n",
    "    \"en_dolma-wiki\",\n",
    "    \"en_dolmino-stackexchange\",\n",
    "    \"en_finemath-4plus\",\n",
    "    \"en_fineweb-eduscore2\",\n",
    "    \"en_fineweb-rest\",\n",
    "    \"en_gsm8k\",\n",
    "    \"en_mathpile\",\n",
    "    \"en_olmo-algebraicstack\",\n",
    "    \"en_olmo-arxiv\",\n",
    "    \"en_olmo-openwebmath\",\n",
    "    \"en_wiki\",\n",
    "    \"ja_fineweb2\",\n",
    "    \"ja_wiki\",\n",
    "    \"ko_fineweb2\",\n",
    "    \"ko_wiki\",\n",
    "    \"zh_fineweb2\",\n",
    "    \"zh_wiki\",\n",
    "]\n",
    "num_tokens = num_tokens[num_tokens[\"subset\"].isin(selected_subsets)].copy()\n",
    "\n",
    "# Number of files\n",
    "len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19125616043765"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total tokens\n",
    "total_tokens = num_tokens[\"tokens\"].sum()\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "code      218478932787\n",
       "en      17784024165462\n",
       "ja        282176188715\n",
       "ko         52097144842\n",
       "zh        788839611959\n",
       "Name: tokens, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens per language\n",
    "tokens_per_language = num_tokens.groupby(\"language\").sum()[\"tokens\"]\n",
    "tokens_per_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "code_olmo-starcoder           104427769064\n",
       "code_stack                    114051163723\n",
       "en_dolma-books                  5494262694\n",
       "en_dolma-pes2o                 62853772802\n",
       "en_dolma-reddit                83015186637\n",
       "en_dolma-wiki                   3896965449\n",
       "en_dolmino-stackexchange        1464772187\n",
       "en_finemath-4plus              10335599308\n",
       "en_fineweb-eduscore2         6187818835090\n",
       "en_fineweb-rest             11366326157218\n",
       "en_gsm8k                           2781710\n",
       "en_mathpile                     9176535715\n",
       "en_olmo-algebraicstack         13280211413\n",
       "en_olmo-arxiv                  22219529548\n",
       "en_olmo-openwebmath            13395295861\n",
       "en_wiki                         4744259830\n",
       "ja_fineweb2                   280894286561\n",
       "ja_wiki                         1281902154\n",
       "ko_fineweb2                    51780848623\n",
       "ko_wiki                          316296219\n",
       "zh_fineweb2                   787999334628\n",
       "zh_wiki                          840277331\n",
       "Name: tokens, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens per subset\n",
    "tokens_per_subset = num_tokens.groupby(\"subset\").sum()[\"tokens\"]\n",
    "tokens_per_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {'en_fineweb-rest': 0.689819})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rates = collections.defaultdict(lambda: 1.0)\n",
    "\n",
    "# Calculate FineWeb sampling rate\n",
    "train_tokens = 15_600_000_000_000\n",
    "fw_rest_tokens = tokens_per_subset[\"en_fineweb-rest\"]\n",
    "fw_rest_train_tokens = train_tokens - (total_tokens - fw_rest_tokens)\n",
    "sampling_rates[\"en_fineweb-rest\"] = fw_rest_train_tokens / fw_rest_tokens\n",
    "sampling_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15600000000048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens[\"sampling_rate\"] = num_tokens[\"subset\"].apply(lambda x: sampling_rates[x])\n",
    "num_tokens[\"sampled_tokens\"] = np.ceil(num_tokens[\"tokens\"] * num_tokens[\"sampling_rate\"]).astype(np.int64)\n",
    "sum(num_tokens[\"sampled_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output corpus config file\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "corpus_prefix=\"/home/shared/experiments/0111_v4-setup\"  # Sakura\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as fp:\n",
    "    print(\"TRAIN_DATA_PATH=(\", file=fp)\n",
    "    print(\"    --data-path\", file=fp)\n",
    "\n",
    "    for idx, r in num_tokens.iterrows():\n",
    "        print(f\"    {r['sampled_tokens']:16d} {corpus_prefix}/{r['filename']}_text_document\", file=fp)\n",
    "\n",
    "    print(\")\", file=fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
