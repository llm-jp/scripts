#!/bin/bash
# List of environment variables and module loads for pretrain tasks

export PRETRAIN_CUDA_VERSION_MAJOR=12
export PRETRAIN_CUDA_VERSION_MINOR=4
export PRETRAIN_CUDA_VERSION_PATCH=1

export PRETRAIN_CUDA_VERSION=${PRETRAIN_CUDA_VERSION_MAJOR}.${PRETRAIN_CUDA_VERSION_MINOR}
export PRETRAIN_CUDA_VERSION_SHORT=${PRETRAIN_CUDA_VERSION_MAJOR}${PRETRAIN_CUDA_VERSION_MINOR}
export PRETRAIN_CUDNN_VERSION=9.5
export PRETRAIN_CUDNN_VERSION_WITH_PATCH=9.5.1
export PRETRAIN_HPCX_VERSION=2.20
export PRETRAIN_NCCL_VERSION=2.25
export PRETRAIN_NCCL_VERSION_WITH_PATCH=2.25.1-1

export PRETRAIN_PYTHON_VERSION=3.10.4
export PRETRAIN_TORCH_VERSION=2.6.0
export PRETRAIN_TORCHVISION_VERSION=0.21.0
export PRETRAIN_APEX_COMMIT=312acb44f9fe05cab8c67bba6daa0e64d3737863
export PRETRAIN_FLASH_ATTENTION_VERSION=2.5.8
export PRETRAIN_TRANSFORMER_ENGINE_VERSION=1.13.0

export PRETRAIN_MEGATRON_TAG=v4
# Ensure the appropriate Huggingface tokenizer is included
# https://github.com/llm-jp/scripts/pull/12#discussion_r1708415209
export PRETRAIN_TOKENIZER_TAG=v3.0b2

source /etc/profile.d/modules.sh
module load cuda/${PRETRAIN_CUDA_VERSION}/${PRETRAIN_CUDA_VERSION}.${PRETRAIN_CUDA_VERSION_PATCH}
module load cudnn/${PRETRAIN_CUDNN_VERSION}/${PRETRAIN_CUDNN_VERSION_WITH_PATCH}
module load hpcx/${PRETRAIN_HPCX_VERSION}
module load nccl/${PRETRAIN_NCCL_VERSION}/${PRETRAIN_NCCL_VERSION_WITH_PATCH}

export LD_LIBRARY_PATH=/usr/lib64:$LD_LIBRARY_PATH