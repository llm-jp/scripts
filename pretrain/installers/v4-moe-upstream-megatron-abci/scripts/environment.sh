#!/bin/bash
# List of environment variables and module loads for pretrain tasks

export PRETRAIN_CUDA_VERSION_MAJOR=12
export PRETRAIN_CUDA_VERSION_MINOR=6
export PRETRAIN_CUDA_VERSION_PATCH=1

export PRETRAIN_CUDA_VERSION=${PRETRAIN_CUDA_VERSION_MAJOR}.${PRETRAIN_CUDA_VERSION_MINOR}
export PRETRAIN_CUDA_VERSION_SHORT=${PRETRAIN_CUDA_VERSION_MAJOR}${PRETRAIN_CUDA_VERSION_MINOR}
export PRETRAIN_CUDNN_VERSION=9.5
export PRETRAIN_CUDNN_VERSION_WITH_PATCH=9.5.1
export PRETRAIN_HPCX_VERSION=2.20
export PRETRAIN_NCCL_VERSION=2.25
export PRETRAIN_NCCL_VERSION_WITH_PATCH=2.25.1-1
export PRETRAIN_GDRCOPY_VERSION=2.4.1

export PRETRAIN_PYTHON_VERSION=3.10.4
export PRETRAIN_TORCH_VERSION=2.8.0
export PRETRAIN_APEX_COMMIT=e13873debc4699d39c6861074b9a3b2a02327f92
export PRETRAIN_FLASH_ATTENTION_VERSION=2.8.1
export PRETRAIN_TRANSFORMER_ENGINE_VERSION=2.8.0
export PRETRAIN_NVSHMEM_VERSION=3.4.5
export PRETRAIN_DEEPEP_VERSION=9af0e0d0e74f3577af1979c9b9e1ac2cad0104ee

# export PRETRAIN_MEGATRON_TAG=v4
export PRETRAIN_MEGATRON_TAG=main
# Ensure the appropriate Huggingface tokenizer is included
# https://github.com/llm-jp/scripts/pull/12#discussion_r1708415209
export PRETRAIN_TOKENIZER_TAG=v3.0b2

source /etc/profile.d/modules.sh
module load cuda/${PRETRAIN_CUDA_VERSION}/${PRETRAIN_CUDA_VERSION}.${PRETRAIN_CUDA_VERSION_PATCH}
module load cudnn/${PRETRAIN_CUDNN_VERSION}/${PRETRAIN_CUDNN_VERSION_WITH_PATCH}
module load hpcx/${PRETRAIN_HPCX_VERSION}
module load nccl/${PRETRAIN_NCCL_VERSION}/${PRETRAIN_NCCL_VERSION_WITH_PATCH}
module load gdrcopy/${PRETRAIN_GDRCOPY_VERSION}

export LD_LIBRARY_PATH=/usr/lib64:$LD_LIBRARY_PATH
